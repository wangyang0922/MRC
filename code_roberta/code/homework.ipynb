{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2697,
     "status": "ok",
     "timestamp": 1595855398904,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "T_6c_DPF83T9",
    "outputId": "8544d19b-2807-4a7a-a187-d18f00961d67"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "import numpy as np\n",
    "from bert4keras.backend import keras, K\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.tokenizers import Tokenizer\n",
    "from bert4keras.optimizers import Adam\n",
    "from bert4keras.snippets import sequence_padding, DataGenerator\n",
    "from bert4keras.snippets import open\n",
    "from keras.layers import Layer, Dense, Permute\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 基本信息\n",
    "maxlen = 128\n",
    "epochs = 20\n",
    "batch_size = 4\n",
    "learing_rate = 2e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4EIYmRCaA_nH"
   },
   "source": [
    "## 设置数据路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1099,
     "status": "ok",
     "timestamp": 1595855539058,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "ItUURTQ183UA"
   },
   "outputs": [],
   "source": [
    "data_dir='./data'\n",
    "output_dir='./data'\n",
    "bert_dir = './data'\n",
    "config_path = f'{bert_dir}/bert_config.json'\n",
    "checkpoint_path = f'{bert_dir}/bert_model.ckpt'\n",
    "dict_path = f'{bert_dir}/vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 983,
     "status": "ok",
     "timestamp": 1595855602931,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "vjf9nl7I83UW"
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    D = []\n",
    "    for d in json.load(open(filename))['data'][0]['paragraphs']:\n",
    "        for qa in d['qas']:\n",
    "            D.append([\n",
    "                qa['id'], d['context'], qa['question'],\n",
    "                [a['text'] for a in qa.get('answers', [])]\n",
    "            ])\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1699,
     "status": "ok",
     "timestamp": 1595855610658,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "w70wRIw883UY"
   },
   "outputs": [],
   "source": [
    "train_data = load_data(\n",
    "    # os.path.join(data_dir,'train.json')\n",
    "    os.path.join(data_dir,'demo_train.json')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k2SDWmUv83Ua"
   },
   "source": [
    "# 建立分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "ok",
     "timestamp": 1595855631388,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "8G1BqYjh83Ub"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K399Sc5E83Ud"
   },
   "source": [
    "# 子串搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 957,
     "status": "ok",
     "timestamp": 1595855636749,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "C2Y8mXlE83Ue"
   },
   "outputs": [],
   "source": [
    "def search(pattern, sequence):\n",
    "    \"\"\"从sequence中寻找子串pattern\n",
    "    如果找到，返回第一个下标；否则返回-1。\n",
    "    \"\"\"\n",
    "    n = len(pattern)\n",
    "    for i in range(len(sequence)):\n",
    "        if sequence[i:i + n] == pattern:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHMtsGYC83Uh"
   },
   "source": [
    "# 数据生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1120,
     "status": "ok",
     "timestamp": 1595855716262,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "fypxJpY583Uh"
   },
   "outputs": [],
   "source": [
    "class data_generator(DataGenerator):\n",
    "    def __iter__(self, random=False):\n",
    "        batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "        for is_end, item in self.sample(random):\n",
    "            context, question, answers = item[1:]\n",
    "            token_ids, segment_ids = tokenizer.encode(\n",
    "                question, context, maxlen=maxlen\n",
    "            )\n",
    "            a = np.random.choice(answers)\n",
    "            a_token_ids = tokenizer.encode(a)[0][1:-1]\n",
    "            start_index = search(a_token_ids, token_ids)\n",
    "            if start_index != -1:\n",
    "                labels = [[start_index], [start_index + len(a_token_ids) - 1]]\n",
    "                batch_token_ids.append(token_ids)\n",
    "                batch_segment_ids.append(segment_ids)\n",
    "                batch_labels.append(labels)\n",
    "                if len(batch_token_ids) == self.batch_size or is_end:\n",
    "                    batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                    batch_segment_ids = sequence_padding(batch_segment_ids)\n",
    "                    batch_labels = sequence_padding(batch_labels)\n",
    "                    yield [batch_token_ids, batch_segment_ids], batch_labels\n",
    "                    batch_token_ids, batch_segment_ids, batch_labels = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fvx3sVXK83Uj"
   },
   "source": [
    "# Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1595855723296,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "jbuoJCYJ83Uk"
   },
   "outputs": [],
   "source": [
    "class MaskedSoftmax(Layer):\n",
    "    \"\"\"\n",
    "    在序列长度那一维进行softmax，并mask掉padding部分\n",
    "    \"\"\"\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask, 2)\n",
    "            inputs = inputs - (1.0 - mask) * 1e12\n",
    "        return K.softmax(inputs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n2vYtLW683Um"
   },
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18452,
     "status": "ok",
     "timestamp": 1595855749908,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "kNmeanl_83Um",
    "outputId": "3164862d-444c-48e6-f31a-2f79a1c9c94c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (Embedding)     (None, None, 1024)   21635072    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, None, 1024)   2048        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, None, 1024)   0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, None, 1024)   524288      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, None, 1024)   2048        Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, None, 1024)   0           Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 1024)   4198400     Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 1024)   0           Embedding-Dropout[0][0]          \n",
      "                                                                 Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward (Feed (None, None, 1024)   8393728     Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Dropo (None, None, 1024)   0           Transformer-0-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Add ( (None, None, 1024)   0           Transformer-0-MultiHeadSelfAttent\n",
      "                                                                 Transformer-0-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Norm  (None, None, 1024)   2048        Transformer-0-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward (Feed (None, None, 1024)   8393728     Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Dropo (None, None, 1024)   0           Transformer-1-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Add ( (None, None, 1024)   0           Transformer-1-MultiHeadSelfAttent\n",
      "                                                                 Transformer-1-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Norm  (None, None, 1024)   2048        Transformer-1-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward (Feed (None, None, 1024)   8393728     Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Dropo (None, None, 1024)   0           Transformer-2-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Add ( (None, None, 1024)   0           Transformer-2-MultiHeadSelfAttent\n",
      "                                                                 Transformer-2-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Norm  (None, None, 1024)   2048        Transformer-2-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward (Feed (None, None, 1024)   8393728     Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Dropo (None, None, 1024)   0           Transformer-3-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Add ( (None, None, 1024)   0           Transformer-3-MultiHeadSelfAttent\n",
      "                                                                 Transformer-3-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Norm  (None, None, 1024)   2048        Transformer-3-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward (Feed (None, None, 1024)   8393728     Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Dropo (None, None, 1024)   0           Transformer-4-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Add ( (None, None, 1024)   0           Transformer-4-MultiHeadSelfAttent\n",
      "                                                                 Transformer-4-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Norm  (None, None, 1024)   2048        Transformer-4-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward (Feed (None, None, 1024)   8393728     Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Dropo (None, None, 1024)   0           Transformer-5-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Add ( (None, None, 1024)   0           Transformer-5-MultiHeadSelfAttent\n",
      "                                                                 Transformer-5-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Norm  (None, None, 1024)   2048        Transformer-5-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward (Feed (None, None, 1024)   8393728     Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Dropo (None, None, 1024)   0           Transformer-6-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Add ( (None, None, 1024)   0           Transformer-6-MultiHeadSelfAttent\n",
      "                                                                 Transformer-6-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Norm  (None, None, 1024)   2048        Transformer-6-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward (Feed (None, None, 1024)   8393728     Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Dropo (None, None, 1024)   0           Transformer-7-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Add ( (None, None, 1024)   0           Transformer-7-MultiHeadSelfAttent\n",
      "                                                                 Transformer-7-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Norm  (None, None, 1024)   2048        Transformer-7-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward (Feed (None, None, 1024)   8393728     Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Dropo (None, None, 1024)   0           Transformer-8-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Add ( (None, None, 1024)   0           Transformer-8-MultiHeadSelfAttent\n",
      "                                                                 Transformer-8-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Norm  (None, None, 1024)   2048        Transformer-8-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward (Feed (None, None, 1024)   8393728     Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Dropo (None, None, 1024)   0           Transformer-9-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Add ( (None, None, 1024)   0           Transformer-9-MultiHeadSelfAttent\n",
      "                                                                 Transformer-9-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Norm  (None, None, 1024)   2048        Transformer-9-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward (Fee (None, None, 1024)   8393728     Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Drop (None, None, 1024)   0           Transformer-10-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Add  (None, None, 1024)   0           Transformer-10-MultiHeadSelfAtten\n",
      "                                                                 Transformer-10-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Norm (None, None, 1024)   2048        Transformer-10-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-10-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward (Fee (None, None, 1024)   8393728     Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Drop (None, None, 1024)   0           Transformer-11-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Add  (None, None, 1024)   0           Transformer-11-MultiHeadSelfAtten\n",
      "                                                                 Transformer-11-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Norm (None, None, 1024)   2048        Transformer-11-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-11-FeedForward-Norm[0\n",
      "                                                                 Transformer-11-FeedForward-Norm[0\n",
      "                                                                 Transformer-11-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-12-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-11-FeedForward-Norm[0\n",
      "                                                                 Transformer-12-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-12-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-FeedForward (Fee (None, None, 1024)   8393728     Transformer-12-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-FeedForward-Drop (None, None, 1024)   0           Transformer-12-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-FeedForward-Add  (None, None, 1024)   0           Transformer-12-MultiHeadSelfAtten\n",
      "                                                                 Transformer-12-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-FeedForward-Norm (None, None, 1024)   2048        Transformer-12-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-12-FeedForward-Norm[0\n",
      "                                                                 Transformer-12-FeedForward-Norm[0\n",
      "                                                                 Transformer-12-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-13-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-12-FeedForward-Norm[0\n",
      "                                                                 Transformer-13-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-13-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-FeedForward (Fee (None, None, 1024)   8393728     Transformer-13-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-FeedForward-Drop (None, None, 1024)   0           Transformer-13-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-FeedForward-Add  (None, None, 1024)   0           Transformer-13-MultiHeadSelfAtten\n",
      "                                                                 Transformer-13-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-FeedForward-Norm (None, None, 1024)   2048        Transformer-13-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-13-FeedForward-Norm[0\n",
      "                                                                 Transformer-13-FeedForward-Norm[0\n",
      "                                                                 Transformer-13-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-14-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-13-FeedForward-Norm[0\n",
      "                                                                 Transformer-14-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-14-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-FeedForward (Fee (None, None, 1024)   8393728     Transformer-14-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-FeedForward-Drop (None, None, 1024)   0           Transformer-14-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-FeedForward-Add  (None, None, 1024)   0           Transformer-14-MultiHeadSelfAtten\n",
      "                                                                 Transformer-14-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-FeedForward-Norm (None, None, 1024)   2048        Transformer-14-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-14-FeedForward-Norm[0\n",
      "                                                                 Transformer-14-FeedForward-Norm[0\n",
      "                                                                 Transformer-14-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-15-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-14-FeedForward-Norm[0\n",
      "                                                                 Transformer-15-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-15-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-FeedForward (Fee (None, None, 1024)   8393728     Transformer-15-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-FeedForward-Drop (None, None, 1024)   0           Transformer-15-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-FeedForward-Add  (None, None, 1024)   0           Transformer-15-MultiHeadSelfAtten\n",
      "                                                                 Transformer-15-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-FeedForward-Norm (None, None, 1024)   2048        Transformer-15-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-15-FeedForward-Norm[0\n",
      "                                                                 Transformer-15-FeedForward-Norm[0\n",
      "                                                                 Transformer-15-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-16-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-15-FeedForward-Norm[0\n",
      "                                                                 Transformer-16-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-16-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-FeedForward (Fee (None, None, 1024)   8393728     Transformer-16-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-FeedForward-Drop (None, None, 1024)   0           Transformer-16-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-FeedForward-Add  (None, None, 1024)   0           Transformer-16-MultiHeadSelfAtten\n",
      "                                                                 Transformer-16-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-FeedForward-Norm (None, None, 1024)   2048        Transformer-16-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-16-FeedForward-Norm[0\n",
      "                                                                 Transformer-16-FeedForward-Norm[0\n",
      "                                                                 Transformer-16-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-17-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-16-FeedForward-Norm[0\n",
      "                                                                 Transformer-17-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-17-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-FeedForward (Fee (None, None, 1024)   8393728     Transformer-17-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-FeedForward-Drop (None, None, 1024)   0           Transformer-17-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-FeedForward-Add  (None, None, 1024)   0           Transformer-17-MultiHeadSelfAtten\n",
      "                                                                 Transformer-17-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-FeedForward-Norm (None, None, 1024)   2048        Transformer-17-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-17-FeedForward-Norm[0\n",
      "                                                                 Transformer-17-FeedForward-Norm[0\n",
      "                                                                 Transformer-17-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-18-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-17-FeedForward-Norm[0\n",
      "                                                                 Transformer-18-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-18-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-FeedForward (Fee (None, None, 1024)   8393728     Transformer-18-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-FeedForward-Drop (None, None, 1024)   0           Transformer-18-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-FeedForward-Add  (None, None, 1024)   0           Transformer-18-MultiHeadSelfAtten\n",
      "                                                                 Transformer-18-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-FeedForward-Norm (None, None, 1024)   2048        Transformer-18-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-18-FeedForward-Norm[0\n",
      "                                                                 Transformer-18-FeedForward-Norm[0\n",
      "                                                                 Transformer-18-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-19-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-18-FeedForward-Norm[0\n",
      "                                                                 Transformer-19-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-19-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-FeedForward (Fee (None, None, 1024)   8393728     Transformer-19-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-FeedForward-Drop (None, None, 1024)   0           Transformer-19-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-FeedForward-Add  (None, None, 1024)   0           Transformer-19-MultiHeadSelfAtten\n",
      "                                                                 Transformer-19-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-FeedForward-Norm (None, None, 1024)   2048        Transformer-19-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-19-FeedForward-Norm[0\n",
      "                                                                 Transformer-19-FeedForward-Norm[0\n",
      "                                                                 Transformer-19-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-20-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-19-FeedForward-Norm[0\n",
      "                                                                 Transformer-20-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-20-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-FeedForward (Fee (None, None, 1024)   8393728     Transformer-20-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-FeedForward-Drop (None, None, 1024)   0           Transformer-20-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-FeedForward-Add  (None, None, 1024)   0           Transformer-20-MultiHeadSelfAtten\n",
      "                                                                 Transformer-20-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-FeedForward-Norm (None, None, 1024)   2048        Transformer-20-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-20-FeedForward-Norm[0\n",
      "                                                                 Transformer-20-FeedForward-Norm[0\n",
      "                                                                 Transformer-20-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-21-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-20-FeedForward-Norm[0\n",
      "                                                                 Transformer-21-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-21-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-FeedForward (Fee (None, None, 1024)   8393728     Transformer-21-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-FeedForward-Drop (None, None, 1024)   0           Transformer-21-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-FeedForward-Add  (None, None, 1024)   0           Transformer-21-MultiHeadSelfAtten\n",
      "                                                                 Transformer-21-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-FeedForward-Norm (None, None, 1024)   2048        Transformer-21-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-21-FeedForward-Norm[0\n",
      "                                                                 Transformer-21-FeedForward-Norm[0\n",
      "                                                                 Transformer-21-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-22-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-21-FeedForward-Norm[0\n",
      "                                                                 Transformer-22-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-22-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-FeedForward (Fee (None, None, 1024)   8393728     Transformer-22-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-FeedForward-Drop (None, None, 1024)   0           Transformer-22-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-FeedForward-Add  (None, None, 1024)   0           Transformer-22-MultiHeadSelfAtten\n",
      "                                                                 Transformer-22-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-FeedForward-Norm (None, None, 1024)   2048        Transformer-22-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-22-FeedForward-Norm[0\n",
      "                                                                 Transformer-22-FeedForward-Norm[0\n",
      "                                                                 Transformer-22-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-23-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-22-FeedForward-Norm[0\n",
      "                                                                 Transformer-23-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-23-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-FeedForward (Fee (None, None, 1024)   8393728     Transformer-23-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-FeedForward-Drop (None, None, 1024)   0           Transformer-23-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-FeedForward-Add  (None, None, 1024)   0           Transformer-23-MultiHeadSelfAtten\n",
      "                                                                 Transformer-23-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-FeedForward-Norm (None, None, 1024)   2048        Transformer-23-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_145 (Dense)               (None, None, 2)      2050        Transformer-23-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "masked_softmax_1 (MaskedSoftmax (None, None, 2)      0           dense_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 2, None)      0           masked_softmax_1[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 324,474,882\n",
      "Trainable params: 324,474,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_transformer_model(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    ")\n",
    "\n",
    "output = Dense(2)(model.output)\n",
    "output = MaskedSoftmax()(output)\n",
    "output = Permute((2, 1))(output)\n",
    "\n",
    "model = Model(model.input, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TTDznSI483Uo"
   },
   "source": [
    "# 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1083,
     "status": "ok",
     "timestamp": 1595855775055,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "aBwxu8Lw83Up"
   },
   "outputs": [],
   "source": [
    "def sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    # y_true需要重新明确一下shape和dtype\n",
    "    y_true = K.reshape(y_true, K.shape(y_pred)[:-1])\n",
    "    y_true = K.cast(y_true, 'int32')\n",
    "    y_true = K.one_hot(y_true, K.shape(y_pred)[2])\n",
    "    # 计算交叉熵\n",
    "    return K.mean(K.categorical_crossentropy(y_true, y_pred))\n",
    "\n",
    "\n",
    "def sparse_accuracy(y_true, y_pred):\n",
    "    # y_true需要重新明确一下shape和dtype\n",
    "    y_true = K.reshape(y_true, K.shape(y_pred)[:-1])\n",
    "    y_true = K.cast(y_true, 'int32')\n",
    "    # 计算准确率\n",
    "    y_pred = K.cast(K.argmax(y_pred, axis=2), 'int32')\n",
    "    return K.mean(K.cast(K.equal(y_true, y_pred), K.floatx()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFxg5d8T83Uq"
   },
   "source": [
    "# 编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1019,
     "status": "ok",
     "timestamp": 1595855789528,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "T-r4oWgd83Ur"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=sparse_categorical_crossentropy,\n",
    "    optimizer=Adam(learing_rate),\n",
    "    metrics=[sparse_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCbOxQOM83Uu"
   },
   "source": [
    "# 答案抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1016,
     "status": "ok",
     "timestamp": 1595855897853,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "kSj4Ri9p83Uu"
   },
   "outputs": [],
   "source": [
    "def extract_answer(question, context, max_a_len=16):\n",
    "    \"\"\"\n",
    "    抽取答案函数\n",
    "    \"\"\"\n",
    "    max_q_len = 64\n",
    "    q_token_ids = tokenizer.encode(question, maxlen=max_q_len)[0]\n",
    "    c_token_ids = tokenizer.encode(\n",
    "        context, maxlen=maxlen - len(q_token_ids) + 1\n",
    "    )[0]\n",
    "    token_ids = q_token_ids + c_token_ids[1:]\n",
    "    segment_ids = [0] * len(q_token_ids) + [1] * (len(c_token_ids) - 1)\n",
    "    c_tokens = tokenizer.tokenize(context)[1:-1]\n",
    "    mapping = tokenizer.rematch(context, c_tokens)\n",
    "    probas = model.predict([[token_ids], [segment_ids]])[0]\n",
    "    probas = probas[:, len(q_token_ids):-1]\n",
    "    start_end, score = None, -1\n",
    "    for start, p_start in enumerate(probas[0]):\n",
    "        for end, p_end in enumerate(probas[1]):\n",
    "            if end >= start and end < start + max_a_len:\n",
    "                if p_start * p_end > score:\n",
    "                    start_end = (start, end)\n",
    "                    score = p_start * p_end\n",
    "    start, end = start_end\n",
    "    return context[mapping[start][0]:mapping[end][-1] + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UPJHj4nS83Uw"
   },
   "source": [
    "# 预测文件生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1088,
     "status": "ok",
     "timestamp": 1595855904541,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "1yBZNbHu83Uw"
   },
   "outputs": [],
   "source": [
    "def predict_to_file(infile, out_file):\n",
    "    \"\"\"预测结果到文件，方便提交\n",
    "    \"\"\"\n",
    "    fw = open(out_file, 'w', encoding='utf-8')\n",
    "    R = {}\n",
    "    for d in tqdm(load_data(infile)):\n",
    "        a = extract_answer(d[2], d[1])\n",
    "        R[d[0]] = a\n",
    "    R = json.dumps(R, ensure_ascii=False, indent=4)\n",
    "    fw.write(R)\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4ceYNdp83Uz"
   },
   "source": [
    "# 官方评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1310,
     "status": "ok",
     "timestamp": 1595855912948,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "wNrSRL0i83Uz"
   },
   "outputs": [],
   "source": [
    "def evaluate(filename):\n",
    "    \"\"\"\n",
    "    评测函数（官方提供评测脚本evaluate.py）\n",
    "    \"\"\"\n",
    "    predict_to_file(filename, filename + '.pred.json')\n",
    "    ref_ans = json.load(io.open(filename))\n",
    "    pred_ans = json.load(io.open(filename + '.pred.json'))\n",
    "    F1, EM, TOTAL, SKIP = src_evaluate(ref_ans, pred_ans)\n",
    "    output_result = OrderedDict()\n",
    "    output_result['F1'] = '%.3f' % F1\n",
    "    output_result['EM'] = '%.3f' % EM\n",
    "    output_result['TOTAL'] = TOTAL\n",
    "    output_result['SKIP'] = SKIP\n",
    "    return output_result\n",
    "\n",
    "\n",
    "class Evaluator(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    评估和保存模型\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.best_val_f1 = 0.\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metrics = evaluate(\n",
    "            os.path.join(data_dir,'dev.json')\n",
    "            # os.path.join(data_dir,'demo_dev.json')\n",
    "        )\n",
    "        if float(metrics['F1']) >= self.best_val_f1:\n",
    "            self.best_val_f1 = float(metrics['F1'])\n",
    "            model.save_weights(os.path.join(output_dir,'roberta_best_model.weights'))\n",
    "            model.save(os.path.join(output_dir,'roberta_best_model.h5'))\n",
    "        metrics['BEST_F1'] = self.best_val_f1\n",
    "        print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rivf9wn883U1"
   },
   "source": [
    "# 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1471,
     "status": "ok",
     "timestamp": 1595855923019,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "z_cSRxhH83U2"
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(train_data, batch_size)\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJi3sNmT83U4"
   },
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "model.fit_generator(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[evaluator]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RjVWAQBF83U6"
   },
   "source": [
    "# 加载最优模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 428210,
     "status": "ok",
     "timestamp": 1595826685996,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "N9nOPUziNhBT",
    "outputId": "980c3238-a34e-4de4-8b69-b38db9a776af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "100%|██████████| 1417/1417 [00:50<00:00, 27.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('F1', '41.801'), ('EM', '26.888'), ('TOTAL', 1417), ('SKIP', 0)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model(os.path.join(output_dir,'roberta_best_model.h5'),custom_objects={'MaskedSoftmax':MaskedSoftmax,'sparse_accuracy':sparse_accuracy})\n",
    "print(evaluate(os.path.join(data_dir,'dev.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-R143V5FZll"
   },
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model=load_model(os.path.join(output_dir,'roberta_best_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m7dtNdk683U7"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(os.path.join(data_dir,'best_model.weights'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "srxSNpeD83U9"
   },
   "source": [
    "# 预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qPD-1vOd83U-"
   },
   "source": [
    "## Test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2136160,
     "status": "ok",
     "timestamp": 1595828394013,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "qMVJ1nig83U-",
    "outputId": "d9c15ece-197c-4456-a313-9aef4edb0c81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [28:26<00:00, 29.29it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_to_file(os.path.join(data_dir,'test1.json'), os.path.join(output_dir,'pred1.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZZDFVTl83VA"
   },
   "source": [
    "## Test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3826850,
     "status": "ok",
     "timestamp": 1595830084711,
     "user": {
      "displayName": "闫强",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64",
      "userId": "07650022386608013289"
     },
     "user_tz": -480
    },
    "id": "EnpQLIO-83VA",
    "outputId": "905852c2-6f07-4e67-8f60-5dc9cc83c79d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [28:09<00:00, 29.59it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_to_file(os.path.join(data_dir,'test2.json'),  os.path.join(output_dir,'pred2.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GrUWFdMc83VC"
   },
   "source": [
    "# 保存上传结果"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2020语言与智能技术竞赛.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
